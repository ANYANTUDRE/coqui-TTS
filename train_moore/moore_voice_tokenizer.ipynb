{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#! pip install transformers datasets tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9480c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip uninstall -y torch\\n!pip install torch==2.4.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip uninstall -y torch\n",
    "!pip install torch==2.4.1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ee46fa715e90ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:35:36.981779Z",
     "start_time": "2024-04-24T00:35:36.930349600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import normalizers\n",
    "from typing import List\n",
    "import re\n",
    "import tokenizers\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from types import NoneType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, HfFolder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Access the token key\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "def login_hugging_face(token: str) -> None:\n",
    "    \"\"\"\n",
    "    Loging to Hugging Face portal with a given token.\n",
    "    \"\"\"\n",
    "    api = HfApi(token=token)\n",
    "    #api.set_access_token(token)\n",
    "    #folder = HfFolder()\n",
    "    #folder.save_token(token)\n",
    "    return None\n",
    "\n",
    "login_hugging_face(HF_TOKEN)\n",
    "print('We are logged in to Hugging Face now!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4173c29d286a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:52:01.299522900Z",
     "start_time": "2024-04-09T00:51:58.471984700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mos_ds = load_dataset(\"ArissBandoss/moore-data-webscraping-full-CSV\", split=\"train\")\n",
    "mos_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d522c52c87647d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T00:52:02.922221500Z",
     "start_time": "2024-04-09T00:52:02.912230600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class VoiceMooreTextPreprocessor:\n",
    "\n",
    "    def preprocess_batch(self, texts: List[str]) -> List[str]:\n",
    "        return [self.preprocess(text) for text in texts]\n",
    "\n",
    "    def preprocess(self, text: str) -> str:\n",
    "        if type(text) == NoneType:\n",
    "            text = str(text)\n",
    "        text = text.lower()\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026ed92078ecc40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:41.286834700Z",
     "start_time": "2024-04-09T10:27:41.280662Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=2000,\n",
    "    special_tokens=[\"[STOP]\", \"[UNK]\", \"[SPACE]\", \"[START]\", \"[mos]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")\n",
    "\n",
    "text_preprocessor = VoiceMooreTextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027bfa5070209f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:45.078568200Z",
     "start_time": "2024-04-09T10:27:45.075470700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_iterator(batch_size=1000):\n",
    "    for i in range(0, len(mos_ds), batch_size):\n",
    "        yield text_preprocessor.preprocess_batch(mos_ds[i: i + batch_size][\"mos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a730cdbc1e9162c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:27:59.113969Z",
     "start_time": "2024-04-09T10:27:47.660547900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(batch_iterator(), trainer=trainer, length=len(mos_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65ae1f96591fa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:00.654940Z",
     "start_time": "2024-04-09T10:28:00.591076600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/teamspace/studios/this_studio/coqui-TTS/train_moore\")\n",
    "print(os.getcwd())\n",
    "tokenizer.save(\"./saved/mos_vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc3955ce86b2e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:08.772023100Z",
     "start_time": "2024-04-09T10:28:07.759462800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = tokenizer.encode_batch(text_preprocessor.preprocess_batch(mos_ds['mos'][:10]))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3d747361b7b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:10.958286900Z",
     "start_time": "2024-04-09T10:28:10.876130Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs[5].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00181372d83aa3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:28:16.448429800Z",
     "start_time": "2024-04-09T10:28:16.386015800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = tokenizer.encode(text_preprocessor.preprocess(\"b sẽn deeg bi wã\"))\n",
    "outputs.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e0ac06e6bafd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:29:16.177405200Z",
     "start_time": "2024-04-09T10:29:16.128536900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def integrate_vocabs(main_vocab_path, mos_vocab_path, output_dir):\n",
    "    # Load the main vocabulary\n",
    "    with open(main_vocab_path, 'r', encoding='utf-8') as f:\n",
    "        main_vocab = json.load(f)\n",
    "    main_tokens = set(main_vocab['model']['vocab'].keys())\n",
    "    next_id = max(main_vocab['model']['vocab'].values()) + 1\n",
    "\n",
    "    # Load the Moore vocabulary\n",
    "    with open(mos_vocab_path, 'r', encoding='utf-8') as f:\n",
    "        mos_vocab = json.load(f)\n",
    "    mos_tokens = set(mos_vocab['model']['vocab'].keys())\n",
    "    \n",
    "    # Add tokens from mos_vocab to main_vocab if they don't exist\n",
    "    for token in mos_tokens:\n",
    "        if token not in main_tokens:\n",
    "            main_vocab['model']['vocab'][token] = next_id\n",
    "            next_id += 1\n",
    "    \n",
    "    # Now for the merges\n",
    "    main_merges = set(main_vocab['model']['merges'])\n",
    "    mos_merges = set(mos_vocab['model']['merges'])\n",
    "\n",
    "    # Add merges from mos_vocab to main_vocab if they don't exist\n",
    "    for merge in mos_merges:\n",
    "        if merge not in main_merges:\n",
    "            main_vocab['model']['merges'].append(merge)\n",
    "\n",
    "    # Save the updated vocabulary\n",
    "    output_vocab_path = os.path.join(output_dir, 'combined_vocab.json')\n",
    "    with open(output_vocab_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(main_vocab, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Updated vocabulary saved to {output_vocab_path}\")\n",
    "    return output_vocab_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c38053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e164a6bdf63f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:29:19.620043300Z",
     "start_time": "2024-04-09T10:29:19.540517Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the paths to your main and Bambara vocab files\n",
    "main_vocab_path = './saved/xtts_default_vocab.json'\n",
    "mos_vocab_path = './saved/mos_vocab.json'\n",
    "output_dir = './saved'\n",
    "\n",
    "# Integrate the Moore vocab into the main vocab and save the updated vocab\n",
    "updated_vocab_path = integrate_vocabs(main_vocab_path, mos_vocab_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434350effaeabdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:30:39.166551900Z",
     "start_time": "2024-04-09T10:30:39.130175300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_tokenizer = Tokenizer.from_file(\"./saved/combined_vocab.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb3daf9aed9256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T10:32:52.032969500Z",
     "start_time": "2024-04-09T10:32:51.972958700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_tokenizer.encode(\"b sẽn deeg bi wã\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb62fee2008e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:35:18.861214900Z",
     "start_time": "2024-04-24T00:28:31.376036700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mos_multi_ds = load_dataset(\"ArissBandoss/sentences-audio-texte-denoised-enhanced\")\n",
    "mos_multi_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46227afef4b0bab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:39:22.567206Z",
     "start_time": "2024-04-24T00:39:22.557579100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_and_save_audio_samples(dataset, speaker_id, num_samples=10, audio_column='audio'):\n",
    "    \"\"\"\n",
    "    Selects a specified number of random audio samples for a given speaker from a dataset,\n",
    "    and saves them to a designated directory.\n",
    "\n",
    "    Args:\n",
    "    dataset (Dataset): The Hugging Face dataset containing audio data.\n",
    "    audio_column (str): The name of the column in the dataset that contains the audio file paths.\n",
    "    speaker_id (str): The speaker ID to filter the audio samples by.\n",
    "    num_samples (int): The number of random samples to select and save.\n",
    "    \"\"\"\n",
    "    # Filter the dataset for the specified speaker\n",
    "    speaker_data = dataset.filter(lambda ex: [x == speaker_id for x in ex['speaker_id']], batched=True, batch_size=100)\n",
    "\n",
    "    # Check if there are enough samples for the requested number\n",
    "    if len(speaker_data) < num_samples:\n",
    "        raise ValueError(\"The number of samples requested exceeds the number available for this speaker.\")\n",
    "\n",
    "    # Randomly select samples\n",
    "    selected_samples = random.sample(list(speaker_data), num_samples)\n",
    "\n",
    "    # Create the directory for the speaker if it does not exist\n",
    "    speaker_dir = f'./reference_audios/speaker_{speaker_id}/'\n",
    "    os.makedirs(speaker_dir, exist_ok=True)\n",
    "\n",
    "    # Save the selected audio files\n",
    "    for index, sample in enumerate(selected_samples):\n",
    "        audio_data = sample[audio_column]['array']\n",
    "        sample_rate = sample[audio_column]['sampling_rate']\n",
    "        destination_path = os.path.join(speaker_dir, f'{index}.wav')\n",
    "        # Write the audio file\n",
    "        sf.write(destination_path, audio_data, sample_rate)\n",
    "        print(f\"Saved: {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95bbe20e390637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T00:56:51.081207900Z",
     "start_time": "2024-04-24T00:56:49.799523300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_and_save_audio_samples(mos_multi_ds['train'], speaker_id=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9560ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
